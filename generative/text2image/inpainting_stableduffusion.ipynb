{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1eac065cdace42c0aa1f322d45ddfa45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_264fde3de5364c639b3994644bb1d90b",
              "IPY_MODEL_5a1fd9028d3a42fa84b99168c9699b15",
              "IPY_MODEL_a05c8fab660a4456b472f0dbb5727e73",
              "IPY_MODEL_f7b423119f204df98a1065760a10a16c"
            ],
            "layout": "IPY_MODEL_e8bede6813244cbc958b2d851fe48123"
          }
        },
        "264fde3de5364c639b3994644bb1d90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d1f77792c184891b6e22cfc574dc85d",
            "placeholder": "​",
            "style": "IPY_MODEL_ec091511f4cf44778deb97888bea4315",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5a1fd9028d3a42fa84b99168c9699b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_08414b15e71c4e2880cd262d62662012",
            "placeholder": "​",
            "style": "IPY_MODEL_0e2aa8ae6545490a9e6d3b49766174b5",
            "value": ""
          }
        },
        "a05c8fab660a4456b472f0dbb5727e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e59d8f3012164b3b89533c4f217f7719",
            "style": "IPY_MODEL_d9899ac4c5184feaa88a85fb4ef8c593",
            "tooltip": ""
          }
        },
        "f7b423119f204df98a1065760a10a16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9011b4a329ce4ef297517fcadc2d46b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c59985db634ccabc71505ab821a273",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e8bede6813244cbc958b2d851fe48123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "9d1f77792c184891b6e22cfc574dc85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec091511f4cf44778deb97888bea4315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08414b15e71c4e2880cd262d62662012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2aa8ae6545490a9e6d3b49766174b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e59d8f3012164b3b89533c4f217f7719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9899ac4c5184feaa88a85fb4ef8c593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9011b4a329ce4ef297517fcadc2d46b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c59985db634ccabc71505ab821a273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tglik/computer_vision/blob/main/generative/text2image/inpainting_stableduffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crd_8vVOpr6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3731b3a1-f24e-48b5-f0ce-0a7f77d49c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug 31 16:42:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install https://github.com/huggingface/diffusers/archive/main.zip -qUU --ignore-installed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnobY4zi0Pjs",
        "outputId": "77eb8eee-73a9-4f43-85ae-7d7ec7bb8307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     - 3.5 kB 8.6 MB/s\r\u001b[K     \\ 6.2 kB 10.8 MB/s\r\u001b[K     | 10 kB 14.0 MB/s\r\u001b[K     / 11 kB 12.3 MB/s\r\u001b[K     - 15 kB 13.3 MB/s\r\u001b[K     \\ 19 kB 14.5 MB/s\r\u001b[K     | 22 kB 15.3 MB/s\r\u001b[K     / 23 kB 15.5 MB/s\r\u001b[K     - 32 kB 16.3 MB/s\r\u001b[K     \\ 40 kB 3.0 MB/s\r\u001b[K     | 44 kB 3.0 MB/s\r\u001b[K     / 48 kB 3.0 MB/s\r\u001b[K     - 51 kB 3.0 MB/s\r\u001b[K     \\ 52 kB 3.0 MB/s\r\u001b[K     | 56 kB 3.0 MB/s\r\u001b[K     / 58 kB 3.0 MB/s\r\u001b[K     - 60 kB 3.0 MB/s\r\u001b[K     \\ 63 kB 3.0 MB/s\r\u001b[K     | 64 kB 3.0 MB/s\r\u001b[K     / 68 kB 3.0 MB/s\r\u001b[K     - 71 kB 3.0 MB/s\r\u001b[K     \\ 72 kB 3.0 MB/s\r\u001b[K     | 77 kB 3.0 MB/s\r\u001b[K     / 81 kB 3.0 MB/s\r\u001b[K     - 83 kB 3.0 MB/s\r\u001b[K     \\ 85 kB 3.0 MB/s\r\u001b[K     | 94 kB 3.0 MB/s\r\u001b[K     / 96 kB 3.0 MB/s\r\u001b[K     - 98 kB 3.0 MB/s\r\u001b[K     \\ 103 kB 3.0 MB/s\r\u001b[K     | 107 kB 3.0 MB/s\r\u001b[K     / 111 kB 3.0 MB/s\r\u001b[K     - 119 kB 3.0 MB/s\r\u001b[K     \\ 122 kB 3.0 MB/s\r\u001b[K     | 123 kB 3.0 MB/s\r\u001b[K     / 127 kB 3.0 MB/s\r\u001b[K     - 131 kB 3.0 MB/s\r\u001b[K     \\ 135 kB 3.0 MB/s\r\u001b[K     | 137 kB 3.0 MB/s\r\u001b[K     / 139 kB 3.0 MB/s\r\u001b[K     - 143 kB 3.0 MB/s\r\u001b[K     \\ 148 kB 3.0 MB/s\r\u001b[K     | 152 kB 3.0 MB/s\r\u001b[K     / 153 kB 3.0 MB/s\r\u001b[K     - 156 kB 3.0 MB/s\r\u001b[K     \\ 158 kB 3.0 MB/s\r\u001b[K     | 160 kB 3.0 MB/s\r\u001b[K     / 164 kB 3.0 MB/s\r\u001b[K     - 167 kB 3.0 MB/s\r\u001b[K     \\ 168 kB 3.0 MB/s\r\u001b[K     | 172 kB 3.0 MB/s\r\u001b[K     / 176 kB 3.0 MB/s\r\u001b[K     - 180 kB 3.0 MB/s\r\u001b[K     \\ 184 kB 3.0 MB/s\r\u001b[K     | 194 kB 3.0 MB/s\r\u001b[K     / 205 kB 3.0 MB/s\r\u001b[K     - 215 kB 3.0 MB/s\r\u001b[K     \\ 220 kB 3.0 MB/s\r\u001b[K     | 224 kB 3.0 MB/s\r\u001b[K     / 234 kB 3.0 MB/s\r\u001b[K     - 245 kB 3.0 MB/s\r\u001b[K     \\ 245 kB 3.0 MB/s\r\u001b[K     | 245 kB 3.0 MB/s\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.1 which is incompatible.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.1 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers -q -UU ftfy gradio  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovksFdT-xrSw",
        "outputId": "3ffc562e-8b72-4f47-ea67-212a9a887277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 112 kB 34.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 752 kB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 43.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 12 kB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 58.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 98 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 59.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 74.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 270 kB 71.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 75.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 148 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 231 kB 74.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 247 kB 72.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 75.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 957 kB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 500 kB 74.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 594 kB 75.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 68.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 427 kB 73.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.9 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "thinc 8.1.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.1 which is incompatible.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.1 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --ignore-installed Pillow==9.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB8OR-JazvRM",
        "outputId": "9bf95fb0-3416-4149-f357-18f2a3f276ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze | grep diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwkN0fHw1I-d",
        "outputId": "b6f13eb6-c0e5-4ec7-952f-2b8681d19659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers @ https://github.com/huggingface/diffusers/archive/main.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "1eac065cdace42c0aa1f322d45ddfa45",
            "264fde3de5364c639b3994644bb1d90b",
            "5a1fd9028d3a42fa84b99168c9699b15",
            "a05c8fab660a4456b472f0dbb5727e73",
            "f7b423119f204df98a1065760a10a16c",
            "e8bede6813244cbc958b2d851fe48123",
            "9d1f77792c184891b6e22cfc574dc85d",
            "ec091511f4cf44778deb97888bea4315",
            "08414b15e71c4e2880cd262d62662012",
            "0e2aa8ae6545490a9e6d3b49766174b5",
            "e59d8f3012164b3b89533c4f217f7719",
            "d9899ac4c5184feaa88a85fb4ef8c593",
            "9011b4a329ce4ef297517fcadc2d46b3",
            "b3c59985db634ccabc71505ab821a273"
          ]
        },
        "id": "4W7bWazLNnjA",
        "outputId": "8db9a242-4307-488f-8f29-1f6139f2dff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eac065cdace42c0aa1f322d45ddfa45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##credit : Hugging Face Team\n",
        "# import inspect\n",
        "# from typing import List, Optional, Union\n",
        "\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# import PIL\n",
        "# from diffusers import AutoencoderKL, DDIMScheduler, DiffusionPipeline, PNDMScheduler, UNet2DConditionModel\n",
        "# from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "# from tqdm.auto import tqdm\n",
        "# from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "\n",
        "# def preprocess_image(image):\n",
        "#     w, h = image.size\n",
        "#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "#     image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "#     image = np.array(image).astype(np.float32) / 255.0\n",
        "#     image = image[None].transpose(0, 3, 1, 2)\n",
        "#     image = torch.from_numpy(image)\n",
        "#     return 2.0 * image - 1.0\n",
        "\n",
        "# def preprocess_mask(mask):\n",
        "#     mask=mask.convert(\"L\")\n",
        "#     w, h = mask.size\n",
        "#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "#     mask = mask.resize((w//8, h//8), resample=PIL.Image.NEAREST)\n",
        "#     mask = np.array(mask).astype(np.float32) / 255.0\n",
        "#     mask = np.tile(mask,(4,1,1))\n",
        "#     mask = mask[None].transpose(0, 1, 2, 3)#what does this step do?\n",
        "#     mask = 1 - mask #repaint white, keep black\n",
        "#     mask = torch.from_numpy(mask)\n",
        "#     return mask\n",
        "\n",
        "\n",
        "# class StableDiffusionInpaintingPipeline(DiffusionPipeline):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         vae: AutoencoderKL,\n",
        "#         text_encoder: CLIPTextModel,\n",
        "#         tokenizer: CLIPTokenizer,\n",
        "#         unet: UNet2DConditionModel,\n",
        "#         scheduler: Union[DDIMScheduler, PNDMScheduler],\n",
        "#         safety_checker: StableDiffusionSafetyChecker,\n",
        "#         feature_extractor: CLIPFeatureExtractor,\n",
        "#     ):\n",
        "#         super().__init__()\n",
        "#         scheduler = scheduler.set_format(\"pt\")\n",
        "#         self.register_modules(\n",
        "#             vae=vae,\n",
        "#             text_encoder=text_encoder,\n",
        "#             tokenizer=tokenizer,\n",
        "#             unet=unet,\n",
        "#             scheduler=scheduler,\n",
        "#             safety_checker=safety_checker,\n",
        "#             feature_extractor=feature_extractor,\n",
        "#         )\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def __call__(\n",
        "#         self,\n",
        "#         prompt: Union[str, List[str]],\n",
        "#         init_image: torch.FloatTensor,\n",
        "#         mask_image: torch.FloatTensor,\n",
        "#         strength: float = 0.8,\n",
        "#         num_inference_steps: Optional[int] = 50,\n",
        "#         guidance_scale: Optional[float] = 7.5,\n",
        "#         eta: Optional[float] = 0.0,\n",
        "#         generator: Optional[torch.Generator] = None,\n",
        "#         output_type: Optional[str] = \"pil\",\n",
        "#     ):\n",
        "\n",
        "#         if isinstance(prompt, str):\n",
        "#             batch_size = 1\n",
        "#         elif isinstance(prompt, list):\n",
        "#             batch_size = len(prompt)\n",
        "#         else:\n",
        "#             raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\n",
        "\n",
        "#         if strength < 0 or strength > 1:\n",
        "#             raise ValueError(f\"The value of strength should in [0.0, 1.0] but is {strength}\")\n",
        "\n",
        "#         # set timesteps\n",
        "#         accepts_offset = \"offset\" in set(inspect.signature(self.scheduler.set_timesteps).parameters.keys())\n",
        "#         extra_set_kwargs = {}\n",
        "#         offset = 0\n",
        "#         if accepts_offset:\n",
        "#             offset = 1\n",
        "#             extra_set_kwargs[\"offset\"] = 1\n",
        "\n",
        "#         self.scheduler.set_timesteps(num_inference_steps, **extra_set_kwargs)\n",
        "\n",
        "#         #preprocess image\n",
        "#         init_image = preprocess_image(init_image).to(self.device)\n",
        "\n",
        "#         # encode the init image into latents and scale the latents\n",
        "#         init_latents = self.vae.encode(init_image).sample()\n",
        "#         init_latents = 0.18215 * init_latents\n",
        "\n",
        "#         # prepare init_latents noise to latents\n",
        "#         init_latents = torch.cat([init_latents] * batch_size)\n",
        "#         init_latents_orig = init_latents\n",
        "\n",
        "#         # preprocess mask\n",
        "#         mask = preprocess_mask(mask_image).to(self.device)\n",
        "#         mask = torch.cat([mask] * batch_size)\n",
        "\n",
        "#         #check sizes\n",
        "#         if not mask.shape == init_latents.shape:\n",
        "#             raise ValueError(f\"The mask and init_image should be the same size!\")\n",
        "\n",
        "\n",
        "#         # get the original timestep using init_timestep\n",
        "#         init_timestep = int(num_inference_steps * strength) + offset\n",
        "#         init_timestep = min(init_timestep, num_inference_steps)\n",
        "#         timesteps = self.scheduler.timesteps[-init_timestep]\n",
        "#         timesteps = torch.tensor([timesteps] * batch_size, dtype=torch.long, device=self.device)\n",
        "\n",
        "#         # add noise to latents using the timesteps\n",
        "#         noise = torch.randn(init_latents.shape, generator=generator, device=self.device)\n",
        "#         init_latents = self.scheduler.add_noise(init_latents, noise, timesteps)\n",
        "\n",
        "#         # get prompt text embeddings\n",
        "#         text_input = self.tokenizer(\n",
        "#             prompt,\n",
        "#             padding=\"max_length\",\n",
        "#             max_length=self.tokenizer.model_max_length,\n",
        "#             truncation=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]\n",
        "\n",
        "#         # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)\n",
        "#         # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`\n",
        "#         # corresponds to doing no classifier free guidance.\n",
        "#         do_classifier_free_guidance = guidance_scale > 1.0\n",
        "#         # get unconditional embeddings for classifier free guidance\n",
        "#         if do_classifier_free_guidance:\n",
        "#             max_length = text_input.input_ids.shape[-1]\n",
        "#             uncond_input = self.tokenizer(\n",
        "#                 [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
        "#             )\n",
        "#             uncond_embeddings = self.text_encoder(uncond_input.input_ids.to(self.device))[0]\n",
        "\n",
        "#             # For classifier free guidance, we need to do two forward passes.\n",
        "#             # Here we concatenate the unconditional and text embeddings into a single batch\n",
        "#             # to avoid doing two forward passes\n",
        "#             text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "#         # prepare extra kwargs for the scheduler step, since not all schedulers have the same signature\n",
        "#         # eta (η) is only used with the DDIMScheduler, it will be ignored for other schedulers.\n",
        "#         # eta corresponds to η in DDIM paper: https://arxiv.org/abs/2010.02502\n",
        "#         # and should be between [0, 1]\n",
        "#         accepts_eta = \"eta\" in set(inspect.signature(self.scheduler.step).parameters.keys())\n",
        "#         extra_step_kwargs = {}\n",
        "#         if accepts_eta:\n",
        "#             extra_step_kwargs[\"eta\"] = eta\n",
        "\n",
        "#         latents = init_latents\n",
        "#         t_start = max(num_inference_steps - init_timestep + offset, 0)\n",
        "#         for i, t in tqdm(enumerate(self.scheduler.timesteps[t_start:])):\n",
        "#             # expand the latents if we are doing classifier free guidance\n",
        "#             latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
        "\n",
        "#             # predict the noise residual\n",
        "#             noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"sample\"]\n",
        "\n",
        "#             # perform guidance\n",
        "#             if do_classifier_free_guidance:\n",
        "#                 noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "#                 noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "#             # compute the previous noisy sample x_t -> x_t-1\n",
        "#             latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs)[\"prev_sample\"]\n",
        "\n",
        "#             #masking\n",
        "#             init_latents_proper = self.scheduler.add_noise(init_latents_orig, noise, t)\n",
        "#             latents = ( init_latents_proper * mask ) + ( latents * (1-mask) )\n",
        "\n",
        "#         # scale and decode the image latents with vae\n",
        "#         latents = 1 / 0.18215 * latents\n",
        "#         image = self.vae.decode(latents)\n",
        "\n",
        "#         image = (image / 2 + 0.5).clamp(0, 1)\n",
        "#         image = image.cpu().permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "#         # run safety checker\n",
        "#         safety_cheker_input = self.feature_extractor(self.numpy_to_pil(image), return_tensors=\"pt\").to(self.device)\n",
        "#         image, has_nsfw_concept = self.safety_checker(images=image, clip_input=safety_cheker_input.pixel_values)\n",
        "\n",
        "#         if output_type == \"pil\":\n",
        "#             image = self.numpy_to_pil(image)\n",
        "\n",
        "#         return {\"sample\": image, \"nsfw_content_detected\": has_nsfw_concept}\n"
      ],
      "metadata": {
        "id": "lP9QRab5JQ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/inference/inpainting.py"
      ],
      "metadata": {
        "id": "Qv2EBO1pPQYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "\n",
        "from torch import autocast\n",
        "import requests\n",
        "import PIL\n",
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline as StableDiffusionInpaintPipeline"
      ],
      "metadata": {
        "id": "RgBbgHv1OFVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "ccRkEh50jCkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
        "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n"
      ],
      "metadata": {
        "id": "oDBr8I9HjFxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = download_image(img_url).resize((512, 512))\n",
        "mask_image = download_image(mask_url).resize((512, 512))"
      ],
      "metadata": {
        "id": "jWnnpa0CjH-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "JbXFEE4BOyQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_image"
      ],
      "metadata": {
        "id": "rqy0D7EbyYyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a kungfu panda sitting on a bench\""
      ],
      "metadata": {
        "id": "agNMXHdERvs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with autocast(\"cuda\"):\n",
        "    images = pipe(prompt=prompt, init_image=init_image, mask_image=mask_image, strength=0.75)[\"sample\"]\n"
      ],
      "metadata": {
        "id": "OFcXcSHCRZkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].save(\"cat_on_bench.png\")\n"
      ],
      "metadata": {
        "id": "F43B99p0R1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "id": "uMqbvbHGR6O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "YVy5QAfcSHkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dict, prompt):\n",
        "  init_img =  dict['image'].convert(\"RGB\").resize((512, 512))\n",
        "  mask_img = dict['mask'].convert(\"RGB\").resize((512, 512))\n",
        "  with autocast(\"cuda\"):\n",
        "    images = pipe(prompt=prompt, init_image=init_img, mask_image=mask_img, strength=0.75)[\"sample\"]\n",
        "\n",
        "  return(images[0])"
      ],
      "metadata": {
        "id": "5iESF7u0lSoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    predict,\n",
        "    title = 'Stable Diffusion In-Painting Tool on Colab with Gradio',\n",
        "    inputs=[\n",
        "        gr.Image(source = 'upload', tool = 'sketch', type = 'pil'),\n",
        "        gr.Textbox(label = 'prompt')\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Image()\n",
        "        ]\n",
        ").launch()"
      ],
      "metadata": {
        "id": "cgMkmlvdkokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0meiHiNymoog"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}